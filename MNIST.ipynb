{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import pgd_, fgsm_, gradient_information, adversarial_accuracy, gradient_norm\n",
    "from Nets import MNIST_Net, Gradient_Masked_MNIST, PGD_MNIST\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport utils, Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a NeuralNet to run experiments on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.284348\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.283884\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 56292/60000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.511254\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.129026\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57427/60000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.208828\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.148857\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57988/60000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.202015\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.189248\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58382/60000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.113353\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.069508\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58654/60000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.170910\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.085779\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58832/60000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.059140\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.283487\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 59051/60000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.203246\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.109669\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 59148/60000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.050289\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.047958\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 59245/60000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.087879\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.025491\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 59307/60000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "epochs = 10\n",
    "log_interval = 500\n",
    "binary = False\n",
    "model = MNIST_Net(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, binary=binary)\n",
    "model.train_on_data(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000\n",
      "1.7999999999999998\n"
     ]
    }
   ],
   "source": [
    "adversarial_dataset = torch.utils.data.Subset(model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "adv = adversarial_accuracy(model, adversarial_loader, attack=pgd_, eps=1, step=0.1, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 28, 28])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adv[4].cpu().detach().squeeze().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Gradient Masked Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.347662\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.682090\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 54318/60000 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.163542\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.159381\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 56770/60000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.102043\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.780907\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 57702/60000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.890302\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.880091\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58135/60000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.694158\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.658931\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58407/60000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.844700\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.602179\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58593/60000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.693250\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.532992\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58687/60000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.760396\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.618667\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58774/60000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.521851\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.450768\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58878/60000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.700904\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.578633\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58920/60000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "masked_model = Gradient_Masked_MNIST(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, eps=1, binary=binary)\n",
    "masked_model.train_on_data(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000\n",
      "24.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.2421e-01, -4.2421e-01, -4.2421e-01,  ...,  7.5787e-02,\n",
       "            2.5673e-01,  4.7579e-01],\n",
       "          [ 4.7579e-01,  5.7579e-01,  2.7579e-01,  ..., -4.2421e-01,\n",
       "           -4.2421e-01, -3.2421e-01],\n",
       "          [ 2.6873e-01,  4.7579e-01,  5.3708e-01,  ..., -3.2421e-01,\n",
       "           -2.3441e-01, -4.2421e-01],\n",
       "          ...,\n",
       "          [ 3.5861e-01,  4.7579e-01,  5.6047e-01,  ..., -4.2421e-01,\n",
       "           -3.2421e-01,  5.7579e-01],\n",
       "          [ 4.7579e-01,  3.6535e-01,  2.9291e-01,  ..., -4.2421e-01,\n",
       "           -1.2421e-01, -4.2421e-01],\n",
       "          [ 1.2735e-01, -4.2421e-01, -4.2421e-01,  ..., -4.2421e-01,\n",
       "            1.7579e-01,  4.7579e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.7579e-01,  7.5787e-02, -3.2421e-01,  ..., -3.0975e-01,\n",
       "           -3.2421e-01, -4.2561e-02],\n",
       "          [-3.3075e-02,  2.7579e-01, -2.2421e-01,  ..., -4.2421e-01,\n",
       "           -1.2421e-01, -1.2421e-01],\n",
       "          [ 7.5787e-02,  1.7579e-01, -3.2421e-01,  ..., -2.9075e-01,\n",
       "           -3.9854e-01,  7.5787e-02],\n",
       "          ...,\n",
       "          [ 7.5787e-02, -1.2421e-01, -3.2373e-01,  ..., -1.2421e-01,\n",
       "            6.3149e-02,  1.3451e-01],\n",
       "          [ 7.5787e-02,  3.5262e-01, -3.2421e-01,  ..., -1.2421e-01,\n",
       "           -2.2085e-01, -2.1242e-04],\n",
       "          [ 7.5787e-02, -1.2421e-01,  1.6222e-02,  ..., -1.0834e-03,\n",
       "            7.5787e-02, -2.2421e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.3602e-01, -2.2421e-01, -2.2975e-02,  ...,  3.7579e-01,\n",
       "            5.8664e-02, -2.7861e-01],\n",
       "          [-4.2421e-01, -4.2421e-01, -2.2421e-01,  ...,  3.7137e-01,\n",
       "           -4.2421e-01, -4.2421e-01],\n",
       "          [-4.2421e-01, -2.6978e-01, -3.2421e-01,  ..., -4.2421e-01,\n",
       "           -4.2421e-01, -3.2421e-01],\n",
       "          ...,\n",
       "          [ 3.8840e-01, -3.2421e-01, -1.5275e-01,  ..., -4.2421e-01,\n",
       "           -3.2421e-01, -1.2421e-01],\n",
       "          [-4.2421e-01, -4.2421e-01, -3.2421e-01,  ...,  1.1659e-01,\n",
       "            4.8833e-01,  4.7579e-01],\n",
       "          [-4.2421e-01, -1.2421e-01, -3.3968e-01,  ...,  4.7579e-01,\n",
       "            5.7579e-01,  5.7579e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.7579e-01,  2.1354e-01, -2.2421e-01,  ..., -2.9101e-01,\n",
       "            7.5787e-02, -4.2421e-01],\n",
       "          [-3.9982e-01, -2.2421e-01, -3.2421e-01,  ..., -3.2421e-01,\n",
       "            5.7579e-01, -4.2421e-01],\n",
       "          [-1.2421e-01, -3.3168e-01, -4.2421e-01,  ...,  3.0169e-02,\n",
       "            2.7579e-01,  4.7579e-01],\n",
       "          ...,\n",
       "          [-4.2421e-01, -2.2421e-01, -4.2421e-01,  ..., -4.2421e-01,\n",
       "            3.2162e-01, -3.2421e-01],\n",
       "          [-4.2421e-01, -3.2421e-01, -3.2421e-01,  ...,  2.8773e-02,\n",
       "            2.2066e-01, -4.2421e-01],\n",
       "          [ 5.7579e-01, -3.2421e-01, -3.2421e-01,  ..., -1.2661e-01,\n",
       "            7.5787e-02, -3.2421e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.9238e-01, -4.2421e-01,  7.5787e-02,  ...,  7.5787e-02,\n",
       "            7.5787e-02,  1.7579e-01],\n",
       "          [-4.2421e-01, -4.2421e-01, -3.2421e-01,  ..., -3.2421e-01,\n",
       "           -8.3692e-02, -4.2421e-01],\n",
       "          [-4.2421e-01,  4.7579e-01,  5.7579e-01,  ...,  5.3746e-01,\n",
       "            1.6598e-01, -2.4213e-02],\n",
       "          ...,\n",
       "          [-4.2421e-01,  2.0778e-01,  7.5787e-02,  ...,  5.7579e-01,\n",
       "            4.9752e-01, -2.4213e-02],\n",
       "          [ 4.7579e-01,  5.7579e-01,  5.7579e-01,  ..., -4.2421e-01,\n",
       "           -4.2421e-01,  3.4028e-01],\n",
       "          [ 5.7579e-01,  5.7579e-01,  5.7579e-01,  ...,  1.7579e-01,\n",
       "           -4.2421e-01, -2.2421e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.2421e-01, -4.2421e-01, -5.8447e-02,  ..., -3.2421e-01,\n",
       "           -1.2421e-01, -1.2421e-01],\n",
       "          [-4.2421e-01, -3.2421e-01, -2.2421e-01,  ..., -3.2421e-01,\n",
       "           -4.2421e-01,  1.0685e-01],\n",
       "          [-3.2421e-01, -4.2421e-01, -3.2421e-01,  ..., -2.3420e-01,\n",
       "           -5.6913e-02,  4.7579e-01],\n",
       "          ...,\n",
       "          [-4.2421e-01, -1.6002e-01, -4.2421e-01,  ...,  5.7579e-01,\n",
       "           -1.2421e-01, -4.2421e-01],\n",
       "          [-1.2421e-01, -1.7056e-01, -4.2421e-01,  ...,  4.7841e-01,\n",
       "            5.7579e-01,  5.7579e-01],\n",
       "          [ 3.7579e-01, -3.2421e-01, -3.2421e-01,  ...,  5.7579e-01,\n",
       "           -2.2421e-01, -2.2421e-01]]]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_dataset = torch.utils.data.Subset(masked_model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "adversarial_accuracy(masked_model, adversarial_loader, attack=pgd_, eps=1, step=0.1, iters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PGD trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.440084\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.302186\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 44334/60000 (74%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.033499\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.735892\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 55060/60000 (92%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.303441\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.235090\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 56897/60000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.475070\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.017604\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 57521/60000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.927771\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.076525\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 58039/60000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.804776\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.797958\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 58277/60000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.983850\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.881364\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58418/60000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.896446\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.914744\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58565/60000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.772248\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.592839\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58692/60000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.590330\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.766379\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58774/60000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pgd_model = PGD_MNIST(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, eps=1, step=0.2, iters=7, binary=binary)\n",
    "pgd_model.train_on_data(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000\n",
      "88.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4242, -0.3242,  0.1626,  ...,  0.5758,  0.5758,  0.2629],\n",
       "          [-0.4242,  0.2758, -0.3242,  ..., -0.4242, -0.2242, -0.3242],\n",
       "          [ 0.0476, -0.4242, -0.3242,  ..., -0.0969, -0.4242, -0.0925],\n",
       "          ...,\n",
       "          [-0.3242, -0.4242, -0.4242,  ..., -0.2242,  0.5758,  0.0100],\n",
       "          [-0.3242, -0.1242,  0.5758,  ..., -0.3242,  0.2482,  0.3758],\n",
       "          [ 0.2758,  0.4758, -0.4242,  ..., -0.4242, -0.4242, -0.2702]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0758, -0.3242, -0.4242,  ..., -0.4242, -0.4242,  0.1758],\n",
       "          [-0.4242, -0.1242,  0.0137,  ..., -0.2242,  0.2758, -0.3242],\n",
       "          [-0.4242,  0.5758, -0.1242,  ..., -0.2242, -0.4242,  0.1547],\n",
       "          ...,\n",
       "          [ 0.5758, -0.2242, -0.3026,  ..., -0.1242, -0.3242,  0.4758],\n",
       "          [ 0.5758, -0.3242,  0.5758,  ...,  0.3679,  0.1406,  0.0758],\n",
       "          [ 0.2576, -0.3242,  0.2531,  ..., -0.1242, -0.4242,  0.0758]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0758,  0.0682,  0.5758,  ..., -0.4242, -0.0389, -0.0242],\n",
       "          [ 0.2758,  0.0758, -0.4242,  ...,  0.5459,  0.2758, -0.0242],\n",
       "          [-0.1242, -0.2945, -0.2242,  ..., -0.4242, -0.4242,  0.0758],\n",
       "          ...,\n",
       "          [-0.4242, -0.2242,  0.5758,  ...,  0.0164, -0.3242,  0.0758],\n",
       "          [-0.0242,  0.2758, -0.4242,  ..., -0.1242, -0.1367, -0.3242],\n",
       "          [-0.1012,  0.3807, -0.3242,  ...,  0.3758,  0.4758, -0.1036]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.4242,  0.5758, -0.3242,  ...,  0.2326, -0.4242, -0.1690],\n",
       "          [-0.4242,  0.4758, -0.3242,  ..., -0.1242, -0.3344,  0.0758],\n",
       "          [-0.3242, -0.3242,  0.3583,  ...,  0.1269, -0.4242, -0.2585],\n",
       "          ...,\n",
       "          [ 0.4758,  0.4758, -0.1242,  ..., -0.0536, -0.3242,  0.3758],\n",
       "          [ 0.4758, -0.4242,  0.5758,  ..., -0.3242, -0.2242,  0.5067],\n",
       "          [ 0.0281,  0.5758, -0.2242,  ..., -0.4242,  0.0758, -0.1002]]],\n",
       "\n",
       "\n",
       "        [[[-0.4242, -0.0242,  0.5758,  ..., -0.3242,  0.5758,  0.2758],\n",
       "          [-0.4242, -0.1699, -0.1242,  ...,  0.0758,  0.2758, -0.4242],\n",
       "          [-0.4242,  0.1385, -0.3242,  ..., -0.4242,  0.5670, -0.4242],\n",
       "          ...,\n",
       "          [-0.4242,  0.2849, -0.1238,  ..., -0.3242, -0.2242,  0.2147],\n",
       "          [-0.3242, -0.3179,  0.5758,  ..., -0.1528,  0.4505,  0.0100],\n",
       "          [ 0.2758,  0.2727, -0.1242,  ..., -0.4242,  0.0629,  0.0758]]],\n",
       "\n",
       "\n",
       "        [[[-0.4242, -0.1242,  0.3758,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242,  0.0958,  0.5696,  ..., -0.3242, -0.0111, -0.4242],\n",
       "          [-0.2242,  0.2299, -0.4242,  ...,  0.3758, -0.1138, -0.0242],\n",
       "          ...,\n",
       "          [ 0.2758, -0.3242, -0.4242,  ..., -0.4242, -0.1242, -0.1242],\n",
       "          [ 0.4758, -0.1242,  0.5758,  ..., -0.2239, -0.0919, -0.1242],\n",
       "          [ 0.3758,  0.5268,  0.5758,  ...,  0.1799, -0.3242, -0.4242]]]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_dataset = torch.utils.data.Subset(pgd_model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "adversarial_accuracy(pgd_model, adversarial_loader, attack=pgd_, eps=1, step=0.1, iters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient masking metric\n",
    "Check alignment of gradient at adv point with (adv point - original point)\n",
    "\n",
    "run pgd until youve crossed the decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2000\n",
    "x = torch.cat([model.train_dataset[i][0].unsqueeze(0) for i in range(n_examples)]).to(device)\n",
    "y = torch.LongTensor([model.train_dataset[i][1] for i in range(n_examples)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817 adv. examples found from 2000 data points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47582945"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(gradient_information(model, x, y, iters=100, eps=0.5, clip_min=model.normalized_min, clip_max=model.normalized_max, device=device).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2000\n",
    "x = torch.cat([masked_model.train_dataset[i][0].unsqueeze(0) for i in range(n_examples)]).to(device)\n",
    "y = torch.LongTensor([masked_model.train_dataset[i][1] for i in range(n_examples)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 adv. examples found from 2000 data points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39267302"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(gradient_information(masked_model, x, y, iters=100, eps=0.5, clip_min=masked_model.normalized_min, clip_max=masked_model.normalized_max, device=device).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGD trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2000\n",
    "x = torch.cat([pgd_model.train_dataset[i][0].unsqueeze(0) for i in range(n_examples)]).to(device)\n",
    "y = torch.LongTensor([pgd_model.train_dataset[i][1] for i in range(n_examples)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 adv. examples found from 2000 data points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17165454"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(gradient_information(pgd_model, x, y, iters=100, eps=0.5, clip_min=pgd_model.normalized_min, clip_max=pgd_model.normalized_max, device=device).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check gradient norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2000\n",
    "x = torch.cat([masked_model.train_dataset[i][0].unsqueeze(0) for i in range(n_examples)]).to(device)\n",
    "y = torch.LongTensor([masked_model.train_dataset[i][1] for i in range(n_examples)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.1198e-05, device='cuda:0'),\n",
       " tensor(1.9965e-05, device='cuda:0'),\n",
       " tensor(2.1970e-05, device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_norm(model, x, y, device=device), gradient_norm(masked_model, x, y, device=device), gradient_norm(pgd_model, x, y, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_train(model, device, train_loader, optimizer, epochs):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs + 1):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            adv_data = pgd_(model, data, target, 0.1, 0.5, iters=7, targeted=False, device=device, clip_min=normalized_min, clip_max=normalized_max)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(adv_data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.735852\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.935562\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.539442\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.542072\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.375298\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.234662\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.547802\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.331915\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.199902\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.282771\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.450014\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.228553\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.216324\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.487287\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.375047\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.198464\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.329873\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.318543\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.161249\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.292225\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.281543\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.347752\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.295510\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.263011\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.110007\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.204418\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.459473\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.264250\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.281901\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.141139\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.151221\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.554338\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.308031\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.278305\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.292606\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.424270\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.162756\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.169706\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.328725\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.124903\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.212911\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.305090\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.225275\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.199005\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.369389\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.138393\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.281870\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.351363\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.108229\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.282040\n"
     ]
    }
   ],
   "source": [
    "undefended_model = type(model)().to(device)\n",
    "undefended_model.load_state_dict(model.state_dict())\n",
    "adv_train(model, device, train_loader, optimizer, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000\n",
      "200 / 1000\n",
      "400 / 1000\n",
      "600 / 1000\n",
      "800 / 1000\n",
      "94.19999999999999\n"
     ]
    }
   ],
   "source": [
    "adversarial_accuracy(model, adversarial_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Box Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_adversarial_accuracy(model, surrogate_model, dataset_loader):\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(dataset_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        adv = pgd_(surrogate_model, data, target, step=0.1, eps=1, iters=10, targeted=False, device=device, clip_min=model.normalized_min, clip_max=model.normalized_max)\n",
    "        output = model(adv)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        if (batch_idx % 100 == 0):\n",
    "            print('{} / {}'.format(batch_idx * dataset_loader.batch_size, len(dataset_loader.dataset)))\n",
    "    print ((correct/len(dataset_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.336703\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.276337\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 55675/60000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.394428\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.327104\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 56708/60000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.376951\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.123159\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 57187/60000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.219509\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.434879\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57507/60000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.155790\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.104833\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57805/60000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.195729\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.250705\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57827/60000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.087341\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.259585\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58056/60000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.214672\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.147782\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58147/60000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.238361\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.219668\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58186/60000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.092994\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.161342\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58311/60000 (97%)\n",
      "\n",
      "0 / 1000\n",
      "92.7\n"
     ]
    }
   ],
   "source": [
    "surrogate_model = MNIST_Net(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, oracle=pgd_model, binary=binary)\n",
    "surrogate_model.train_on_data(epochs)\n",
    "adversarial_dataset = torch.utils.data.Subset(pgd_model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "black_box_adversarial_accuracy(pgd_model, surrogate_model, adversarial_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312138\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.323271\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 56043/60000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.389748\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.343549\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 56960/60000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.072214\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.191582\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 57303/60000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.089042\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.148751\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57661/60000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.073518\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.212289\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57853/60000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.146805\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.062624\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58059/60000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.260564\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.303039\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58217/60000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.057608\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.121253\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58270/60000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.130435\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.106230\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58399/60000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.050250\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.089033\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58490/60000 (97%)\n",
      "\n",
      "0 / 1000\n",
      "71.1\n"
     ]
    }
   ],
   "source": [
    "surrogate_model = MNIST_Net(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, oracle=masked_model, binary=binary)\n",
    "surrogate_model.train_on_data(epochs)\n",
    "adversarial_dataset = torch.utils.data.Subset(masked_model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "black_box_adversarial_accuracy(masked_model, surrogate_model, adversarial_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-env] *",
   "language": "python",
   "name": "conda-env-pytorch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
