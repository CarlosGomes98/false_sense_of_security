{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated notebook. Dont want to delete yet as might be useful to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import pgd_, fgsm_, gradient_information, adversarial_accuracy, gradient_norm\n",
    "from Nets import MNIST_Net, Gradient_Masked_MNIST, PGD_MNIST\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport utils, Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a NeuralNet to run experiments on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.292113\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.628917\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 56407/60000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.252576\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.204431\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57364/60000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.174934\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.216482\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57909/60000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.132875\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.209403\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58259/60000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.215176\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.236372\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58535/60000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.159329\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.032738\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58771/60000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.112809\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.168115\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58964/60000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.063674\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.024824\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 59056/60000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.023815\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.116701\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 59191/60000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.143445\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.040890\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 59267/60000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "epochs = 10\n",
    "log_interval = 500\n",
    "binary = False\n",
    "model = MNIST_Net(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, binary=binary)\n",
    "model.train_on_data(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000\n",
      "1.7000000000000002\n"
     ]
    }
   ],
   "source": [
    "adversarial_dataset = torch.utils.data.Subset(model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "adv = adversarial_accuracy(model, adversarial_loader, attack=pgd_, eps=1, step=0.1, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adv[4].cpu().detach().squeeze().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Gradient Masked Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.387771\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.509459\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 55302/60000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.101734\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.170438\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 56061/60000 (93%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.161760\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.067289\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 57664/60000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.831446\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.856744\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 58108/60000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.803693\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.544233\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58451/60000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.684746\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.839471\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58668/60000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.633153\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.699867\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58769/60000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.466634\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.692779\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58855/60000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.496455\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.475473\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58942/60000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.522878\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.628622\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 59046/60000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "masked_model = Gradient_Masked_MNIST(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, eps=1, binary=binary)\n",
    "masked_model.train_on_data(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000\n",
      "10.299999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2758, -0.4242, -0.1242,  ..., -0.4242, -0.4242,  0.0910],\n",
       "          [ 0.2758, -0.4242,  0.4758,  ..., -0.2622, -0.4242, -0.2242],\n",
       "          [ 0.4758, -0.4242,  0.4758,  ..., -0.4242, -0.1151,  0.0390],\n",
       "          ...,\n",
       "          [-0.4242,  0.4758, -0.4242,  ...,  0.5758, -0.4242,  0.3840],\n",
       "          [-0.4242,  0.4758, -0.4242,  ...,  0.4809, -0.4242,  0.3758],\n",
       "          [-0.4242,  0.5758, -0.4242,  ..., -0.2242, -0.4242,  0.4758]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0055, -0.4242, -0.2242,  ..., -0.1242, -0.4242, -0.4242],\n",
       "          [ 0.5758,  0.1758, -0.4242,  ...,  0.1758, -0.3604,  0.1758],\n",
       "          [-0.2242, -0.3643, -0.3902,  ...,  0.3758, -0.4242,  0.2758],\n",
       "          ...,\n",
       "          [-0.4242,  0.5758, -0.4242,  ..., -0.4242,  0.5758, -0.4242],\n",
       "          [-0.3242,  0.5758, -0.4242,  ..., -0.4242,  0.4700, -0.3859],\n",
       "          [-0.2242,  0.4758,  0.0758,  ..., -0.4242,  0.5758, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4758, -0.4242,  0.1598,  ...,  0.0758,  0.0758,  0.1990],\n",
       "          [ 0.5758, -0.0972, -0.1054,  ..., -0.3443,  0.5758,  0.1532],\n",
       "          [ 0.0758,  0.3528, -0.3242,  ..., -0.4242,  0.0291, -0.2242],\n",
       "          ...,\n",
       "          [ 0.3758, -0.4242,  0.5758,  ...,  0.3175, -0.4242,  0.0758],\n",
       "          [ 0.4076, -0.4242,  0.4758,  ...,  0.5758, -0.4242, -0.4242],\n",
       "          [ 0.5758, -0.4242,  0.4668,  ...,  0.1925, -0.4242, -0.1070]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.4758,  0.2500, -0.1242,  ..., -0.4242,  0.3507,  0.0758],\n",
       "          [-0.3242, -0.3242, -0.3242,  ..., -0.4242,  0.2758, -0.2242],\n",
       "          [-0.3242,  0.1335, -0.3242,  ..., -0.4242,  0.1552, -0.3242],\n",
       "          ...,\n",
       "          [ 0.5758, -0.1884,  0.4032,  ...,  0.5669, -0.4242,  0.2758],\n",
       "          [ 0.3758,  0.2758,  0.2758,  ...,  0.0758, -0.4242,  0.0758],\n",
       "          [ 0.5496, -0.4242,  0.5301,  ..., -0.1242,  0.0222, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[-0.3242,  0.5758, -0.4242,  ...,  0.2758, -0.4242,  0.0156],\n",
       "          [ 0.2758,  0.5758,  0.5758,  ...,  0.2758, -0.4242,  0.3166],\n",
       "          [ 0.5758, -0.3242, -0.3242,  ...,  0.2758, -0.4242,  0.1758],\n",
       "          ...,\n",
       "          [ 0.5385, -0.4242,  0.5758,  ..., -0.4242,  0.3911, -0.4242],\n",
       "          [ 0.4758, -0.4242,  0.5376,  ..., -0.4242, -0.3242, -0.2242],\n",
       "          [ 0.2758,  0.2758,  0.5758,  ..., -0.3242,  0.0061,  0.1758]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5758, -0.2242, -0.3242,  ..., -0.1242, -0.4242,  0.0758],\n",
       "          [-0.3242, -0.4242, -0.3242,  ..., -0.4242,  0.5758,  0.4829],\n",
       "          [ 0.0779, -0.4242, -0.0469,  ...,  0.3758,  0.0459, -0.3242],\n",
       "          ...,\n",
       "          [ 0.5758,  0.2447,  0.0471,  ..., -0.4153, -0.0843, -0.1242],\n",
       "          [-0.2794, -0.4242, -0.3242,  ...,  0.1213, -0.4242, -0.0817],\n",
       "          [ 0.1758, -0.4242, -0.3242,  ..., -0.2949,  0.0758, -0.3242]]]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_dataset = torch.utils.data.Subset(masked_model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "adversarial_accuracy(masked_model, adversarial_loader, attack=pgd_, eps=1, step=0.1, iters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PGD trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.485074\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.117442\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 52127/60000 (87%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.831671\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.460413\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 56105/60000 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.383873\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.422800\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 56789/60000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.112520\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.211908\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 57570/60000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.917755\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.845841\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 57946/60000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.741741\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.745767\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58115/60000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.973186\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.507953\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58375/60000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.491308\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.614406\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58488/60000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.547132\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.503477\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58543/60000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.675428\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.458251\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58689/60000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pgd_model = PGD_MNIST(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, eps=1, step=0.2, iters=7, binary=binary)\n",
    "pgd_model.train_on_data(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000\n",
      "88.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4242,  0.2354, -0.4242,  ..., -0.1242,  0.0758,  0.0758],\n",
       "          [ 0.4775, -0.4242, -0.3242,  ..., -0.4242, -0.2242,  0.4758],\n",
       "          [-0.2714, -0.4242, -0.1242,  ...,  0.0997, -0.4242,  0.5758],\n",
       "          ...,\n",
       "          [-0.4242,  0.0511,  0.5758,  ..., -0.4242, -0.0242,  0.1468],\n",
       "          [-0.3242, -0.3242, -0.3242,  ..., -0.4242, -0.4242, -0.3242],\n",
       "          [-0.1532, -0.4242,  0.1758,  ...,  0.2758, -0.3242, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4758,  0.4758, -0.4242,  ...,  0.5758, -0.0242,  0.0310],\n",
       "          [-0.3242, -0.4242,  0.0758,  ..., -0.4242, -0.4242, -0.1242],\n",
       "          [-0.1242, -0.4242,  0.5469,  ..., -0.4242,  0.0758,  0.0027],\n",
       "          ...,\n",
       "          [ 0.5758, -0.4242, -0.3242,  ..., -0.3242, -0.4242, -0.3242],\n",
       "          [-0.4242, -0.1242,  0.3758,  ...,  0.2758, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.2242,  0.2758,  ...,  0.5758, -0.4242, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4837, -0.4242,  0.5758,  ...,  0.2758, -0.3242, -0.3242],\n",
       "          [ 0.3758, -0.4242,  0.4221,  ..., -0.1242,  0.2682,  0.5758],\n",
       "          [-0.4242,  0.3722,  0.4758,  ...,  0.2758, -0.3242,  0.5758],\n",
       "          ...,\n",
       "          [-0.2242, -0.3242,  0.2937,  ...,  0.3758, -0.2086,  0.5758],\n",
       "          [ 0.2247, -0.0242, -0.0242,  ...,  0.0758, -0.3242, -0.2242],\n",
       "          [-0.3944,  0.5758,  0.5758,  ..., -0.1242, -0.4242, -0.4242]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.3131, -0.1494, -0.3242,  ...,  0.3158, -0.4242,  0.1758],\n",
       "          [ 0.4758,  0.2758, -0.3242,  ..., -0.2242,  0.0758,  0.2758],\n",
       "          [ 0.2758, -0.1780, -0.0853,  ...,  0.4758, -0.0423, -0.1122],\n",
       "          ...,\n",
       "          [ 0.2758, -0.3242, -0.4242,  ..., -0.1242,  0.1294,  0.1758],\n",
       "          [ 0.2758, -0.2242, -0.4242,  ..., -0.3242,  0.0993, -0.0242],\n",
       "          [ 0.3758,  0.5569,  0.2758,  ...,  0.1002, -0.4242, -0.2242]]],\n",
       "\n",
       "\n",
       "        [[[-0.2242,  0.1865, -0.4242,  ...,  0.1758,  0.1758, -0.4242],\n",
       "          [-0.4242, -0.2242, -0.4242,  ..., -0.3242, -0.3242,  0.1027],\n",
       "          [-0.3242, -0.2242, -0.1242,  ..., -0.1242,  0.5758,  0.0313],\n",
       "          ...,\n",
       "          [ 0.5580, -0.3242, -0.4242,  ..., -0.1242,  0.0758,  0.5758],\n",
       "          [ 0.2758, -0.4242, -0.4242,  ..., -0.4242, -0.2242, -0.4242],\n",
       "          [-0.3242,  0.0758, -0.4242,  ...,  0.2758, -0.4242,  0.4758]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0758, -0.3242,  0.1758,  ...,  0.4758, -0.4242,  0.2758],\n",
       "          [-0.1242, -0.1242, -0.2994,  ..., -0.3242,  0.1932, -0.1242],\n",
       "          [-0.0796, -0.2720, -0.1242,  ..., -0.4242, -0.4242,  0.3960],\n",
       "          ...,\n",
       "          [ 0.5758,  0.5758,  0.3368,  ..., -0.0990,  0.0758,  0.2758],\n",
       "          [ 0.1586,  0.1567,  0.0113,  ..., -0.1242, -0.1242, -0.1242],\n",
       "          [ 0.0758,  0.1287, -0.4242,  ...,  0.1758, -0.2242,  0.5758]]]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_dataset = torch.utils.data.Subset(pgd_model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "adversarial_accuracy(pgd_model, adversarial_loader, attack=pgd_, eps=1, step=0.1, iters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient masking metric\n",
    "Check alignment of gradient at adv point with (adv point - original point)\n",
    "\n",
    "run pgd until youve crossed the decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2000\n",
    "x = torch.cat([model.train_dataset[i][0].unsqueeze(0) for i in range(n_examples)]).to(device)\n",
    "y = torch.LongTensor([model.train_dataset[i][1] for i in range(n_examples)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 adv. examples found from 2000 data points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55944264"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(gradient_information(model, x, y, iters=500, eps=100, clip_min=model.normalized_min, clip_max=model.normalized_max, device=device).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2000\n",
    "x = torch.cat([masked_model.train_dataset[i][0].unsqueeze(0) for i in range(n_examples)]).to(device)\n",
    "y = torch.LongTensor([masked_model.train_dataset[i][1] for i in range(n_examples)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 adv. examples found from 2000 data points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49094316"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(gradient_information(masked_model, x, y, iters=500, eps=100, clip_min=masked_model.normalized_min, clip_max=masked_model.normalized_max, device=device).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGD trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2000\n",
    "x = torch.cat([pgd_model.train_dataset[i][0].unsqueeze(0) for i in range(n_examples)]).to(device)\n",
    "y = torch.LongTensor([pgd_model.train_dataset[i][1] for i in range(n_examples)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 adv. examples found from 2000 data points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45576453"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(gradient_information(pgd_model, x, y, iters=500, eps=100, clip_min=pgd_model.normalized_min, clip_max=pgd_model.normalized_max, device=device).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check gradient norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2000\n",
    "x = torch.cat([masked_model.train_dataset[i][0].unsqueeze(0) for i in range(n_examples)]).to(device)\n",
    "y = torch.LongTensor([masked_model.train_dataset[i][1] for i in range(n_examples)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.5361e-05, device='cuda:0'),\n",
       " tensor(1.5415e-05, device='cuda:0'),\n",
       " tensor(1.2171e-05, device='cuda:0'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_norm(model, x, y, device=device), gradient_norm(masked_model, x, y, device=device), gradient_norm(pgd_model, x, y, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_train(model, device, train_loader, optimizer, epochs):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs + 1):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            adv_data = pgd_(model, data, target, 0.1, 0.5, iters=7, targeted=False, device=device, clip_min=normalized_min, clip_max=normalized_max)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(adv_data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.735852\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.935562\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.539442\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.542072\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.375298\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.234662\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.547802\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.331915\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.199902\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.282771\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.450014\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.228553\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.216324\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.487287\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.375047\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.198464\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.329873\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.318543\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.161249\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.292225\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.281543\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.347752\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.295510\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.263011\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.110007\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.204418\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.459473\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.264250\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.281901\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.141139\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.151221\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.554338\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.308031\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.278305\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.292606\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.424270\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.162756\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.169706\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.328725\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.124903\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.212911\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.305090\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.225275\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.199005\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.369389\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.138393\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.281870\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.351363\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.108229\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.282040\n"
     ]
    }
   ],
   "source": [
    "undefended_model = type(model)().to(device)\n",
    "undefended_model.load_state_dict(model.state_dict())\n",
    "adv_train(model, device, train_loader, optimizer, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000\n",
      "200 / 1000\n",
      "400 / 1000\n",
      "600 / 1000\n",
      "800 / 1000\n",
      "94.19999999999999\n"
     ]
    }
   ],
   "source": [
    "adversarial_accuracy(model, adversarial_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Box Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_adversarial_accuracy(model, surrogate_model, dataset_loader):\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(dataset_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        adv = pgd_(surrogate_model, data, target, step=0.1, eps=1, iters=10, targeted=False, device=device, clip_min=model.normalized_min, clip_max=model.normalized_max)\n",
    "        output = model(adv)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        if (batch_idx % 100 == 0):\n",
    "            print('{} / {}'.format(batch_idx * dataset_loader.batch_size, len(dataset_loader.dataset)))\n",
    "    print ((correct/len(dataset_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.336703\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.276337\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 55675/60000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.394428\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.327104\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 56708/60000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.376951\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.123159\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 57187/60000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.219509\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.434879\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57507/60000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.155790\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.104833\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57805/60000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.195729\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.250705\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57827/60000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.087341\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.259585\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58056/60000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.214672\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.147782\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58147/60000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.238361\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.219668\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58186/60000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.092994\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.161342\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58311/60000 (97%)\n",
      "\n",
      "0 / 1000\n",
      "92.7\n"
     ]
    }
   ],
   "source": [
    "surrogate_model = MNIST_Net(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, oracle=pgd_model, binary=binary)\n",
    "surrogate_model.train_on_data(epochs)\n",
    "adversarial_dataset = torch.utils.data.Subset(pgd_model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "black_box_adversarial_accuracy(pgd_model, surrogate_model, adversarial_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312138\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.323271\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 56043/60000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.389748\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.343549\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 56960/60000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.072214\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.191582\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 57303/60000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.089042\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.148751\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57661/60000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.073518\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.212289\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 57853/60000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.146805\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.062624\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58059/60000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.260564\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.303039\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58217/60000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.057608\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.121253\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58270/60000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.130435\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.106230\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58399/60000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.050250\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.089033\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 58490/60000 (97%)\n",
      "\n",
      "0 / 1000\n",
      "71.1\n"
     ]
    }
   ],
   "source": [
    "surrogate_model = MNIST_Net(device=device, log_interval=log_interval, batch_size=batch_size, test_batch_size=test_batch_size, oracle=masked_model, binary=binary)\n",
    "surrogate_model.train_on_data(epochs)\n",
    "adversarial_dataset = torch.utils.data.Subset(masked_model.test_dataset, [i for i in range(1000)])\n",
    "adversarial_loader = torch.utils.data.DataLoader(adversarial_dataset, batch_size=32, num_workers=2, shuffle=False)\n",
    "black_box_adversarial_accuracy(masked_model, surrogate_model, adversarial_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
