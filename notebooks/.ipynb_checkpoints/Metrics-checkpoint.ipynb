{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import LinfPGD, FGSM\n",
    "from advertorch.attacks import LinfSPSAAttack\n",
    "from trainers import Trainer, FGSMTrainer\n",
    "from robustbench.model_zoo.models import Carmon2019UnlabeledNet\n",
    "from utils import adversarial_accuracy, fgsm_, gradient_norm\n",
    "import eagerpy as ep\n",
    "from Nets import CIFAR_Wide_Res_Net, CIFAR_Res_Net\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport Nets, trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device = torch.device(\"cuda\")\n",
    "batch_size = 128\n",
    "# remove the normalize\n",
    "transform = transform = transforms.Compose(\n",
    "            [transforms.ToTensor()]\n",
    ")\n",
    "        \n",
    "normalized_min = (0 - 0.5) / 0.5\n",
    "normalized_max = (1 - 0.5) / 0.5\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                  shuffle=True, num_workers=2)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False,\n",
    "                               download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                 shuffle=False, num_workers=2)\n",
    "classes = classes = ('plane', 'car', 'bird', 'cat',\n",
    "   'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Regular CIFAR-10 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CIFAR_Wide_Res_Net(device).eval()\n",
    "model.load_state_dict(torch.load(\"models/cifar_wide_res_net_norm.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 Model trained with large FGSM steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CIFAR_Wide_Res_Net:\n\tMissing key(s) in state_dict: \"block1.layer.0.bn1.weight\", \"block1.layer.0.bn1.bias\", \"block1.layer.0.bn1.running_mean\", \"block1.layer.0.bn1.running_var\", \"block1.layer.0.conv1.weight\", \"block1.layer.0.bn2.weight\", \"block1.layer.0.bn2.bias\", \"block1.layer.0.bn2.running_mean\", \"block1.layer.0.bn2.running_var\", \"block1.layer.0.conv2.weight\", \"block1.layer.0.convShortcut.weight\", \"block1.layer.1.bn1.weight\", \"block1.layer.1.bn1.bias\", \"block1.layer.1.bn1.running_mean\", \"block1.layer.1.bn1.running_var\", \"block1.layer.1.conv1.weight\", \"block1.layer.1.bn2.weight\", \"block1.layer.1.bn2.bias\", \"block1.layer.1.bn2.running_mean\", \"block1.layer.1.bn2.running_var\", \"block1.layer.1.conv2.weight\", \"block1.layer.2.bn1.weight\", \"block1.layer.2.bn1.bias\", \"block1.layer.2.bn1.running_mean\", \"block1.layer.2.bn1.running_var\", \"block1.layer.2.conv1.weight\", \"block1.layer.2.bn2.weight\", \"block1.layer.2.bn2.bias\", \"block1.layer.2.bn2.running_mean\", \"block1.layer.2.bn2.running_var\", \"block1.layer.2.conv2.weight\", \"block1.layer.3.bn1.weight\", \"block1.layer.3.bn1.bias\", \"block1.layer.3.bn1.running_mean\", \"block1.layer.3.bn1.running_var\", \"block1.layer.3.conv1.weight\", \"block1.layer.3.bn2.weight\", \"block1.layer.3.bn2.bias\", \"block1.layer.3.bn2.running_mean\", \"block1.layer.3.bn2.running_var\", \"block1.layer.3.conv2.weight\", \"sub_block1.layer.0.bn1.weight\", \"sub_block1.layer.0.bn1.bias\", \"sub_block1.layer.0.bn1.running_mean\", \"sub_block1.layer.0.bn1.running_var\", \"sub_block1.layer.0.conv1.weight\", \"sub_block1.layer.0.bn2.weight\", \"sub_block1.layer.0.bn2.bias\", \"sub_block1.layer.0.bn2.running_mean\", \"sub_block1.layer.0.bn2.running_var\", \"sub_block1.layer.0.conv2.weight\", \"sub_block1.layer.0.convShortcut.weight\", \"sub_block1.layer.1.bn1.weight\", \"sub_block1.layer.1.bn1.bias\", \"sub_block1.layer.1.bn1.running_mean\", \"sub_block1.layer.1.bn1.running_var\", \"sub_block1.layer.1.conv1.weight\", \"sub_block1.layer.1.bn2.weight\", \"sub_block1.layer.1.bn2.bias\", \"sub_block1.layer.1.bn2.running_mean\", \"sub_block1.layer.1.bn2.running_var\", \"sub_block1.layer.1.conv2.weight\", \"sub_block1.layer.2.bn1.weight\", \"sub_block1.layer.2.bn1.bias\", \"sub_block1.layer.2.bn1.running_mean\", \"sub_block1.layer.2.bn1.running_var\", \"sub_block1.layer.2.conv1.weight\", \"sub_block1.layer.2.bn2.weight\", \"sub_block1.layer.2.bn2.bias\", \"sub_block1.layer.2.bn2.running_mean\", \"sub_block1.layer.2.bn2.running_var\", \"sub_block1.layer.2.conv2.weight\", \"sub_block1.layer.3.bn1.weight\", \"sub_block1.layer.3.bn1.bias\", \"sub_block1.layer.3.bn1.running_mean\", \"sub_block1.layer.3.bn1.running_var\", \"sub_block1.layer.3.conv1.weight\", \"sub_block1.layer.3.bn2.weight\", \"sub_block1.layer.3.bn2.bias\", \"sub_block1.layer.3.bn2.running_mean\", \"sub_block1.layer.3.bn2.running_var\", \"sub_block1.layer.3.conv2.weight\", \"block2.layer.0.bn1.weight\", \"block2.layer.0.bn1.bias\", \"block2.layer.0.bn1.running_mean\", \"block2.layer.0.bn1.running_var\", \"block2.layer.0.conv1.weight\", \"block2.layer.0.bn2.weight\", \"block2.layer.0.bn2.bias\", \"block2.layer.0.bn2.running_mean\", \"block2.layer.0.bn2.running_var\", \"block2.layer.0.conv2.weight\", \"block2.layer.0.convShortcut.weight\", \"block2.layer.1.bn1.weight\", \"block2.layer.1.bn1.bias\", \"block2.layer.1.bn1.running_mean\", \"block2.layer.1.bn1.running_var\", \"block2.layer.1.conv1.weight\", \"block2.layer.1.bn2.weight\", \"block2.layer.1.bn2.bias\", \"block2.layer.1.bn2.running_mean\", \"block2.layer.1.bn2.running_var\", \"block2.layer.1.conv2.weight\", \"block2.layer.2.bn1.weight\", \"block2.layer.2.bn1.bias\", \"block2.layer.2.bn1.running_mean\", \"block2.layer.2.bn1.running_var\", \"block2.layer.2.conv1.weight\", \"block2.layer.2.bn2.weight\", \"block2.layer.2.bn2.bias\", \"block2.layer.2.bn2.running_mean\", \"block2.layer.2.bn2.running_var\", \"block2.layer.2.conv2.weight\", \"block2.layer.3.bn1.weight\", \"block2.layer.3.bn1.bias\", \"block2.layer.3.bn1.running_mean\", \"block2.layer.3.bn1.running_var\", \"block2.layer.3.conv1.weight\", \"block2.layer.3.bn2.weight\", \"block2.layer.3.bn2.bias\", \"block2.layer.3.bn2.running_mean\", \"block2.layer.3.bn2.running_var\", \"block2.layer.3.conv2.weight\", \"block3.layer.0.bn1.weight\", \"block3.layer.0.bn1.bias\", \"block3.layer.0.bn1.running_mean\", \"block3.layer.0.bn1.running_var\", \"block3.layer.0.conv1.weight\", \"block3.layer.0.bn2.weight\", \"block3.layer.0.bn2.bias\", \"block3.layer.0.bn2.running_mean\", \"block3.layer.0.bn2.running_var\", \"block3.layer.0.conv2.weight\", \"block3.layer.0.convShortcut.weight\", \"block3.layer.1.bn1.weight\", \"block3.layer.1.bn1.bias\", \"block3.layer.1.bn1.running_mean\", \"block3.layer.1.bn1.running_var\", \"block3.layer.1.conv1.weight\", \"block3.layer.1.bn2.weight\", \"block3.layer.1.bn2.bias\", \"block3.layer.1.bn2.running_mean\", \"block3.layer.1.bn2.running_var\", \"block3.layer.1.conv2.weight\", \"block3.layer.2.bn1.weight\", \"block3.layer.2.bn1.bias\", \"block3.layer.2.bn1.running_mean\", \"block3.layer.2.bn1.running_var\", \"block3.layer.2.conv1.weight\", \"block3.layer.2.bn2.weight\", \"block3.layer.2.bn2.bias\", \"block3.layer.2.bn2.running_mean\", \"block3.layer.2.bn2.running_var\", \"block3.layer.2.conv2.weight\", \"block3.layer.3.bn1.weight\", \"block3.layer.3.bn1.bias\", \"block3.layer.3.bn1.running_mean\", \"block3.layer.3.bn1.running_var\", \"block3.layer.3.conv1.weight\", \"block3.layer.3.bn2.weight\", \"block3.layer.3.bn2.bias\", \"block3.layer.3.bn2.running_mean\", \"block3.layer.3.bn2.running_var\", \"block3.layer.3.conv2.weight\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.0.shortcut.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.0.shortcut.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.shortcut.0.weight\", \"layer4.0.shortcut.1.weight\", \"layer4.0.shortcut.1.bias\", \"layer4.0.shortcut.1.running_mean\", \"layer4.0.shortcut.1.running_var\", \"layer4.0.shortcut.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"linear.weight\", \"linear.bias\". \n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).\n\tsize mismatch for bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([640]).\n\tsize mismatch for bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([640]).\n\tsize mismatch for bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([640]).\n\tsize mismatch for bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([640]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c0a18efe2761>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfgsm_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCIFAR_Wide_Res_Net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfgsm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models/cifar_wide_res_net_fgsm06_20e.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1045\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CIFAR_Wide_Res_Net:\n\tMissing key(s) in state_dict: \"block1.layer.0.bn1.weight\", \"block1.layer.0.bn1.bias\", \"block1.layer.0.bn1.running_mean\", \"block1.layer.0.bn1.running_var\", \"block1.layer.0.conv1.weight\", \"block1.layer.0.bn2.weight\", \"block1.layer.0.bn2.bias\", \"block1.layer.0.bn2.running_mean\", \"block1.layer.0.bn2.running_var\", \"block1.layer.0.conv2.weight\", \"block1.layer.0.convShortcut.weight\", \"block1.layer.1.bn1.weight\", \"block1.layer.1.bn1.bias\", \"block1.layer.1.bn1.running_mean\", \"block1.layer.1.bn1.running_var\", \"block1.layer.1.conv1.weight\", \"block1.layer.1.bn2.weight\", \"block1.layer.1.bn2.bias\", \"block1.layer.1.bn2.running_mean\", \"block1.layer.1.bn2.running_var\", \"block1.layer.1.conv2.weight\", \"block1.layer.2.bn1.weight\", \"block1.layer.2.bn1.bias\", \"block1.layer.2.bn1.running_mean\", \"block1.layer.2.bn1.running_var\", \"block1.layer.2.conv1.weight\", \"block1.layer.2.bn2.weight\", \"block1.layer.2.bn2.bias\", \"block1.layer.2.bn2.running_mean\", \"block1.layer.2.bn2.running_var\", \"block1.layer.2.conv2.weight\", \"block1.layer.3.bn1.weight\", \"block1.layer.3.bn1.bias\", \"block1.layer.3.bn1.running_mean\", \"block1.layer.3.bn1.running_var\", \"block1.layer.3.conv1.weight\", \"block1.layer.3.bn2.weight\", \"block1.layer.3.bn2.bias\", \"block1.layer.3.bn2.running_mean\", \"block1.layer.3.bn2.running_var\", \"block1.layer.3.conv2.weight\", \"sub_block1.layer.0.bn1.weight\", \"sub_block1.layer.0.bn1.bias\", \"sub_block1.layer.0.bn1.running_mean\", \"sub_block1.layer.0.bn1.running_var\", \"sub_block1.layer.0.conv1.weight\", \"sub_block1.layer.0.bn2.weight\", \"sub_block1.layer.0.bn2.bias\", \"sub_block1.layer.0.bn2.running_mean\", \"sub_block1.layer.0.bn2.running_var\", \"sub_block1.layer.0.conv2.weight\", \"sub_block1.layer.0.convShortcut.weight\", \"sub_block1.layer.1.bn1.weight\", \"sub_block1.layer.1.bn1.bias\", \"sub_block1.layer.1.bn1.running_mean\", \"sub_block1.layer.1.bn1.running_var\", \"sub_block1.layer.1.conv1.weight\", \"sub_block1.layer.1.bn2.weight\", \"sub_block1.layer.1.bn2.bias\", \"sub_block1.layer.1.bn2.running_mean\", \"sub_block1.layer.1.bn2.running_var\", \"sub_block1.layer.1.conv2.weight\", \"sub_block1.layer.2.bn1.weight\", \"sub_block1.layer.2.bn1.bias\", \"sub_block1.layer.2.bn1.running_mean\", \"sub_block1.layer.2.bn1.running_var\", \"sub_block1.layer.2.conv1.weight\", \"sub_block1.layer.2.bn2.weight\", \"sub_block1.layer.2.bn2.bias\", \"sub_block1.layer.2.bn2.running_mean\", \"sub_block1.layer.2.bn2.running_var\", \"sub_block1.layer.2.conv2.weight\", \"sub_block1.layer.3.bn1.weight\", \"sub_block1.layer.3.bn1.bias\", \"sub_block1.layer.3.bn1.running_mean\", \"sub_block1.layer.3.bn1.running_var\", \"sub_block1.layer.3.conv1.weight\", \"sub_block1.layer.3.bn2.weight\", \"sub_block1.layer.3.bn2.bias\", \"sub_block1.layer.3.bn2.running_mean\", \"sub_block1.layer.3.bn2.running_var\", \"sub_block1.layer.3.conv2.weight\", \"block2.layer.0.bn1.weight\", \"block2.layer.0.bn1.bias\", \"block2.layer.0.bn1.running_mean\", \"block2.layer.0.bn1.running_var\", \"block2.layer.0.conv1.weight\", \"block2.layer.0.bn2.weight\", \"block2.layer.0.bn2.bias\", \"block2.layer.0.bn2.running_mean\", \"block2.layer.0.bn2.running_var\", \"block2.layer.0.conv2.weight\", \"block2.layer.0.convShortcut.weight\", \"block2.layer.1.bn1.weight\", \"block2.layer.1.bn1.bias\", \"block2.layer.1.bn1.running_mean\", \"block2.layer.1.bn1.running_var\", \"block2.layer.1.conv1.weight\", \"block2.layer.1.bn2.weight\", \"block2.layer.1.bn2.bias\", \"block2.layer.1.bn2.running_mean\", \"block2.layer.1.bn2.running_var\", \"block2.layer.1.conv2.weight\", \"block2.layer.2.bn1.weight\", \"block2.layer.2.bn1.bias\", \"block2.layer.2.bn1.running_mean\", \"block2.layer.2.bn1.running_var\", \"block2.layer.2.conv1.weight\", \"block2.layer.2.bn2.weight\", \"block2.layer.2.bn2.bias\", \"block2.layer.2.bn2.running_mean\", \"block2.layer.2.bn2.running_var\", \"block2.layer.2.conv2.weight\", \"block2.layer.3.bn1.weight\", \"block2.layer.3.bn1.bias\", \"block2.layer.3.bn1.running_mean\", \"block2.layer.3.bn1.running_var\", \"block2.layer.3.conv1.weight\", \"block2.layer.3.bn2.weight\", \"block2.layer.3.bn2.bias\", \"block2.layer.3.bn2.running_mean\", \"block2.layer.3.bn2.running_var\", \"block2.layer.3.conv2.weight\", \"block3.layer.0.bn1.weight\", \"block3.layer.0.bn1.bias\", \"block3.layer.0.bn1.running_mean\", \"block3.layer.0.bn1.running_var\", \"block3.layer.0.conv1.weight\", \"block3.layer.0.bn2.weight\", \"block3.layer.0.bn2.bias\", \"block3.layer.0.bn2.running_mean\", \"block3.layer.0.bn2.running_var\", \"block3.layer.0.conv2.weight\", \"block3.layer.0.convShortcut.weight\", \"block3.layer.1.bn1.weight\", \"block3.layer.1.bn1.bias\", \"block3.layer.1.bn1.running_mean\", \"block3.layer.1.bn1.running_var\", \"block3.layer.1.conv1.weight\", \"block3.layer.1.bn2.weight\", \"block3.layer.1.bn2.bias\", \"block3.layer.1.bn2.running_mean\", \"block3.layer.1.bn2.running_var\", \"block3.layer.1.conv2.weight\", \"block3.layer.2.bn1.weight\", \"block3.layer.2.bn1.bias\", \"block3.layer.2.bn1.running_mean\", \"block3.layer.2.bn1.running_var\", \"block3.layer.2.conv1.weight\", \"block3.layer.2.bn2.weight\", \"block3.layer.2.bn2.bias\", \"block3.layer.2.bn2.running_mean\", \"block3.layer.2.bn2.running_var\", \"block3.layer.2.conv2.weight\", \"block3.layer.3.bn1.weight\", \"block3.layer.3.bn1.bias\", \"block3.layer.3.bn1.running_mean\", \"block3.layer.3.bn1.running_var\", \"block3.layer.3.conv1.weight\", \"block3.layer.3.bn2.weight\", \"block3.layer.3.bn2.bias\", \"block3.layer.3.bn2.running_mean\", \"block3.layer.3.bn2.running_var\", \"block3.layer.3.conv2.weight\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.num_batches_tracked\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.0.shortcut.1.num_batches_tracked\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.num_batches_tracked\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.0.shortcut.1.num_batches_tracked\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.num_batches_tracked\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.shortcut.0.weight\", \"layer4.0.shortcut.1.weight\", \"layer4.0.shortcut.1.bias\", \"layer4.0.shortcut.1.running_mean\", \"layer4.0.shortcut.1.running_var\", \"layer4.0.shortcut.1.num_batches_tracked\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.num_batches_tracked\", \"linear.weight\", \"linear.bias\". \n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).\n\tsize mismatch for bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([640]).\n\tsize mismatch for bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([640]).\n\tsize mismatch for bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([640]).\n\tsize mismatch for bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([640])."
     ]
    }
   ],
   "source": [
    "fgsm_model = CIFAR_Wide_Res_Net(device).eval()\n",
    "fgsm_model.load_state_dict(torch.load(\"models/cifar_wide_res_net_fgsm06_20e.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check gradient norms\n",
    "Try plotting gradient norms throughout training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 5000\n",
    "subset = torch.utils.data.Subset(train_dataset, np.random.randint(0, len(test_dataset), size=subset_size).tolist())\n",
    "subset_loader = torch.utils.data.DataLoader(subset, batch_size=batch_size,\n",
    "                                 shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\nException raised from createCublasHandle at ..\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:8 (most recent call first):\n00007FFB3C9275A200007FFB3C927540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFADEE8AEA800007FFADEE89E70 torch_cuda.dll!at::cuda::getCurrentCUDASparseHandle [<unknown file> @ <unknown line number>]\n00007FFADEE8A7D800007FFADEE89E70 torch_cuda.dll!at::cuda::getCurrentCUDASparseHandle [<unknown file> @ <unknown line number>]\n00007FFADEE8B66700007FFADEE8B1A0 torch_cuda.dll!at::cuda::getCurrentCUDABlasHandle [<unknown file> @ <unknown line number>]\n00007FFADEE8B24700007FFADEE8B1A0 torch_cuda.dll!at::cuda::getCurrentCUDABlasHandle [<unknown file> @ <unknown line number>]\n00007FFADEE8320700007FFADEE824B0 torch_cuda.dll!at::native::sparse_mask_cuda [<unknown file> @ <unknown line number>]\n00007FFADE38CA9700007FFADE38B990 torch_cuda.dll!at::native::lerp_cuda_tensor_out [<unknown file> @ <unknown line number>]\n00007FFADE38E4D200007FFADE38DF60 torch_cuda.dll!at::native::addmm_out_cuda [<unknown file> @ <unknown line number>]\n00007FFADE38F64300007FFADE38F560 torch_cuda.dll!at::native::mm_cuda [<unknown file> @ <unknown line number>]\n00007FFADEEF1B0F00007FFADEE8E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFADEEE1B2200007FFADEE8E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFAD6FAD94900007FFAD6FA8FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFAD6FE057700007FFAD6FE0520 torch_cpu.dll!at::mm [<unknown file> @ <unknown line number>]\n00007FFAD833EC7900007FFAD824E010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFAD6AF715700007FFAD6AF6290 torch_cpu.dll!at::indexing::TensorIndex::boolean [<unknown file> @ <unknown line number>]\n00007FFAD6FAD94900007FFAD6FA8FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFAD70C210700007FFAD70C20B0 torch_cpu.dll!at::Tensor::mm [<unknown file> @ <unknown line number>]\n00007FFAD81DB71100007FFAD81DA760 torch_cpu.dll!torch::autograd::profiler::Event::kind [<unknown file> @ <unknown line number>]\n00007FFAD81916D800007FFAD8191580 torch_cpu.dll!torch::autograd::generated::AddmmBackward::apply [<unknown file> @ <unknown line number>]\n00007FFAD8187E9100007FFAD8187B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFAD86EF9BA00007FFAD86EF300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFAD86F03AD00007FFAD86EFFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFAD86F4FE200007FFAD86F4CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFAD86F4C4100007FFAD86F4BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FFB172708F700007FFB17249F80 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFAD86EBF1400007FFAD86EB780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFB6B2114C200007FFB6B211430 ucrtbase.dll!configthreadlocale [<unknown file> @ <unknown line number>]\n00007FFB6C0D703400007FFB6C0D7020 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFB6D79CEC100007FFB6D79CEA0 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5aff20f1ced9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Libraries\\Documents\\false_sense_of_security\\utils.py\u001b[0m in \u001b[0;36mgradient_norm\u001b[1;34m(model, data_loader, device)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch-env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\nException raised from createCublasHandle at ..\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:8 (most recent call first):\n00007FFB3C9275A200007FFB3C927540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFADEE8AEA800007FFADEE89E70 torch_cuda.dll!at::cuda::getCurrentCUDASparseHandle [<unknown file> @ <unknown line number>]\n00007FFADEE8A7D800007FFADEE89E70 torch_cuda.dll!at::cuda::getCurrentCUDASparseHandle [<unknown file> @ <unknown line number>]\n00007FFADEE8B66700007FFADEE8B1A0 torch_cuda.dll!at::cuda::getCurrentCUDABlasHandle [<unknown file> @ <unknown line number>]\n00007FFADEE8B24700007FFADEE8B1A0 torch_cuda.dll!at::cuda::getCurrentCUDABlasHandle [<unknown file> @ <unknown line number>]\n00007FFADEE8320700007FFADEE824B0 torch_cuda.dll!at::native::sparse_mask_cuda [<unknown file> @ <unknown line number>]\n00007FFADE38CA9700007FFADE38B990 torch_cuda.dll!at::native::lerp_cuda_tensor_out [<unknown file> @ <unknown line number>]\n00007FFADE38E4D200007FFADE38DF60 torch_cuda.dll!at::native::addmm_out_cuda [<unknown file> @ <unknown line number>]\n00007FFADE38F64300007FFADE38F560 torch_cuda.dll!at::native::mm_cuda [<unknown file> @ <unknown line number>]\n00007FFADEEF1B0F00007FFADEE8E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFADEEE1B2200007FFADEE8E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFAD6FAD94900007FFAD6FA8FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFAD6FE057700007FFAD6FE0520 torch_cpu.dll!at::mm [<unknown file> @ <unknown line number>]\n00007FFAD833EC7900007FFAD824E010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFAD6AF715700007FFAD6AF6290 torch_cpu.dll!at::indexing::TensorIndex::boolean [<unknown file> @ <unknown line number>]\n00007FFAD6FAD94900007FFAD6FA8FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFAD70C210700007FFAD70C20B0 torch_cpu.dll!at::Tensor::mm [<unknown file> @ <unknown line number>]\n00007FFAD81DB71100007FFAD81DA760 torch_cpu.dll!torch::autograd::profiler::Event::kind [<unknown file> @ <unknown line number>]\n00007FFAD81916D800007FFAD8191580 torch_cpu.dll!torch::autograd::generated::AddmmBackward::apply [<unknown file> @ <unknown line number>]\n00007FFAD8187E9100007FFAD8187B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFAD86EF9BA00007FFAD86EF300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFAD86F03AD00007FFAD86EFFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFAD86F4FE200007FFAD86F4CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFAD86F4C4100007FFAD86F4BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FFB172708F700007FFB17249F80 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFAD86EBF1400007FFAD86EB780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFB6B2114C200007FFB6B211430 ucrtbase.dll!configthreadlocale [<unknown file> @ <unknown line number>]\n00007FFB6C0D703400007FFB6C0D7020 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFB6D79CEC100007FFB6D79CEA0 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n"
     ]
    }
   ],
   "source": [
    "plt.hist(gradient_norm(model, subset_loader, device=device).detach().cpu().numpy(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(gradient_norm(fgsm_model, subset_loader, device=device).detach().cpu().numpy(), bins=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-env] *",
   "language": "python",
   "name": "conda-env-pytorch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
